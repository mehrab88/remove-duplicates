import os
import hashlib

def hash_file(filepath):
    """ØªÙˆÙ„ÛŒØ¯ Ù‡Ø´ SHA256 Ø¨Ø±Ø§ÛŒ Ù…Ø­ØªÙˆØ§ÛŒ ÙØ§ÛŒÙ„"""
    with open(filepath, 'rb') as f:
        return hashlib.sha256(f.read()).hexdigest()

def find_and_remove_duplicates(folder_path):
    hashes = {}
    duplicates = []

    for root, dirs, files in os.walk(folder_path):
        for filename in files:
            filepath = os.path.join(root, filename)
            file_hash = hash_file(filepath)

            if file_hash in hashes:
                print(f"ğŸ” Duplicate found: {filepath} (same as {hashes[file_hash]})")
                os.remove(filepath)
                duplicates.append(filepath)
            else:
                hashes[file_hash] = filepath

    print(f"\nâœ… Done! {len(duplicates)} duplicate files removed.")

# Ù…Ø³ÛŒØ± ÙÙˆÙ„Ø¯Ø± Ø±Ø§ Ø§ÛŒÙ†Ø¬Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†:
folder_path = "/path/to/your/folder"
find_and_remove_duplicates(folder_path)
